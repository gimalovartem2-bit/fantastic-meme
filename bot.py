import logging
import re
import json
import aiohttp
import ssl
from collections import Counter
import sys
from typing import Dict, List, Optional, Tuple
import asyncio
import base64
import uuid
import requests

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ Python
print(f"Python version: {sys.version}")

try:
    from telegram import Update, ReplyKeyboardMarkup, KeyboardButton
    from telegram.ext import (
        Application,
        CommandHandler,
        MessageHandler,
        ConversationHandler,
        ContextTypes,
        filters
    )

    print("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ telegram —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
except ImportError as e:
    print(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É:")
    print("1. –û—Ç–∫—Ä–æ–π—Ç–µ —Ç–µ—Ä–º–∏–Ω–∞–ª PyCharm (–≤–∫–ª–∞–¥–∫–∞ Terminal –≤–Ω–∏–∑—É)")
    print("2. –í–≤–µ–¥–∏—Ç–µ: pip install python-telegram-bot")
    print("3. –ò–ª–∏: python -m pip install python-telegram-bot")
    sys.exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ==================== –ù–ê–°–¢–†–û–ô–ö–ò GIGACHAT API ====================
GIGACHAT_CLIENT_ID = "019c1ed5-8a08-703f-a5d8-71572a5105d2"
GIGACHAT_CLIENT_SECRET = "MDE5YzFlZDUtOGEwOC03MDNmLWE1ZDgtNzE1NzJhNTEwNWQyOjkwYzJjNDk1LTNhYzYtNDlmMC1hMmRlLTdjNjQ5OWQ3ZjI4Yg=="
GIGACHAT_SCOPE = "GIGACHAT_API_PERS"

# URL –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –∑–∞–ø—Ä–æ—Å–æ–≤
GIGACHAT_AUTH_URL = "https://ngw.devices.sberbank.ru:9443/api/v2/oauth"
GIGACHAT_API_URL = "https://gigachat.devices.sberbank.ru/api/v1/chat/completions"


# ==================== –ë–ê–ó–û–í–´–ô –ö–õ–ê–°–° –î–õ–Ø GIGACHAT API ====================

class GigaChatBase:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GigaChat API"""

    def __init__(self, client_id: str, client_secret: str):
        self.client_id = client_id
        self.client_secret = client_secret
        self.access_token = None
        self.token_expiry = 0
        self.session: Optional[aiohttp.ClientSession] = None
        self.timeout = aiohttp.ClientTimeout(total=45)

        # SSL –∫–æ–Ω—Ç–µ–∫—Å—Ç
        self.ssl_context = ssl.create_default_context()
        self.ssl_context.check_hostname = False
        self.ssl_context.verify_mode = ssl.CERT_NONE

    async def get_session(self) -> aiohttp.ClientSession:
        """–°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–µ—Å—Å–∏—é"""
        if self.session is None or self.session.closed:
            connector = aiohttp.TCPConnector(ssl=self.ssl_context)
            self.session = aiohttp.ClientSession(timeout=self.timeout, connector=connector)
        return self.session

    async def get_access_token(self) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç access token –¥–ª—è GigaChat API"""
        import time
        if self.access_token and time.time() < self.token_expiry:
            return self.access_token

        try:
            session = await self.get_session()

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º client_secret –Ω–∞–ø—Ä—è–º—É—é –∫–∞–∫ base64
            auth_base64 = self.client_secret

            headers = {
                'Authorization': f'Basic {auth_base64}',
                'RqUID': str(uuid.uuid4()),
                'Content-Type': 'application/x-www-form-urlencoded',
                'Accept': 'application/json'
            }

            data = {'scope': GIGACHAT_SCOPE}

            async with session.post(GIGACHAT_AUTH_URL, headers=headers, data=data, ssl=self.ssl_context) as response:
                response_text = await response.text()

                if response.status == 200:
                    result = json.loads(response_text)
                    self.access_token = result.get('access_token')
                    expires_in = result.get('expires_in', 1800)
                    self.token_expiry = time.time() + expires_in - 300
                    logger.info(f"‚úÖ –¢–æ–∫–µ–Ω GigaChat –ø–æ–ª—É—á–µ–Ω")
                    return self.access_token
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞: {response.status}")
                    return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–æ–∫–µ–Ω–∞: {e}")
            return None

    async def make_gigachat_request(self, system_prompt: str, user_prompt: str) -> Optional[Dict]:
        """–î–µ–ª–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ GigaChat API"""
        access_token = await self.get_access_token()
        if not access_token:
            return None

        try:
            session = await self.get_session()

            headers = {
                'Authorization': f'Bearer {access_token}',
                'Content-Type': 'application/json',
                'Accept': 'application/json'
            }

            data = {
                "model": "GigaChat",
                "messages": [
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": user_prompt
                    }
                ],
                "temperature": 0.1,
                "max_tokens": 2000,
                "stream": False
            }

            async with session.post(GIGACHAT_API_URL, headers=headers, json=data, ssl=self.ssl_context) as response:
                if response.status == 200:
                    result = await response.json()
                    if 'choices' in result and len(result['choices']) > 0:
                        message = result['choices'][0].get('message', {})
                        return {'success': True, 'response': message.get('content', '')}

                return {'success': False, 'error': f'Status: {response.status}'}

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ GigaChat: {e}")
            return {'success': False, 'error': str(e)}

    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–µ—Å—Å–∏—é"""
        if self.session and not self.session.closed:
            await self.session.close()


# ==================== –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ò–ò-–ê–ù–ê–õ–ò–ó–ê–¢–û–† ====================

class GigaChatUniversalAnalyzer(GigaChatBase):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ GigaChat"""

    async def analyze_text(self, text: str, analysis_type: str) -> Dict:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text.strip():
            return {
                'success': True,
                'analysis': '–¢–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π',
                'analysis_type': analysis_type,
                'source': 'gigachat'
            }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º system_prompt –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
        system_prompts = {
            'text_analysis': """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É —Ç–µ–∫—Å—Ç–∞. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {
                "statistics": {
                    "characters": —á–∏—Å–ª–æ,
                    "words": —á–∏—Å–ª–æ, 
                    "sentences": —á–∏—Å–ª–æ,
                    "average_word_length": —á–∏—Å–ª–æ,
                    "average_sentence_length": —á–∏—Å–ª–æ
                },
                "language_style": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∏–ª—è (—Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π/–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π/—Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∏ —Ç.–¥.)",
                "complexity": "–æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (–ø—Ä–æ—Å—Ç–æ–π/—Å—Ä–µ–¥–Ω–∏–π/—Å–ª–æ–∂–Ω—ã–π)",
                "readability_score": —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 100,
                "key_themes": ["—Ç–µ–º–∞1", "—Ç–µ–º–∞2", "—Ç–µ–º–∞3"],
                "emotional_tone": "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –æ–∫—Ä–∞—Å–∫–∞",
                "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2"]
            }
            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.""",

            'morphology': """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –°–¥–µ–ª–∞–π –ø–æ–ª–Ω—ã–π –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å–ª–æ–≤–∞. –û—Ç–≤–µ—á–∞–π –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {
                "word": "–∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ",
                "part_of_speech": "—á–∞—Å—Ç—å —Ä–µ—á–∏",
                "grammatical_features": {
                    "case": "–ø–∞–¥–µ–∂",
                    "number": "—á–∏—Å–ª–æ",
                    "gender": "—Ä–æ–¥", 
                    "person": "–ª–∏—Ü–æ",
                    "tense": "–≤—Ä–µ–º—è",
                    "mood": "–Ω–∞–∫–ª–æ–Ω–µ–Ω–∏–µ",
                    "voice": "–∑–∞–ª–æ–≥",
                    "aspect": "–≤–∏–¥"
                },
                "initial_form": "–Ω–∞—á–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞",
                "morphological_analysis": "–ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä –ø–æ —Å–æ—Å—Ç–∞–≤—É",
                "syntactic_role": "—Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è —Ä–æ–ª—å –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏",
                "examples": ["–ø—Ä–∏–º–µ—Ä1", "–ø—Ä–∏–º–µ—Ä2"]
            }
            –ï—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –≤–µ—Ä–Ω–∏ –æ—à–∏–±–∫—É –≤ –ø–æ–ª–µ "error".
            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.""",

            'phonetics': """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ñ–æ–Ω–µ—Ç–∏–∫–µ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –°–¥–µ–ª–∞–π —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞. –û—Ç–≤–µ—á–∞–π –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {
                "word": "–∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ",
                "transcription": "—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö",
                "syllables": ["—Å–ª–æ–≥1", "—Å–ª–æ–≥2"],
                "syllable_count": —á–∏—Å–ª–æ,
                "stress_syllable": –Ω–æ–º–µ—Ä —É–¥–∞—Ä–Ω–æ–≥–æ —Å–ª–æ–≥–∞ (–Ω–∞—á–∏–Ω–∞—è —Å 1),
                "sound_analysis": {
                    "vowels": —á–∏—Å–ª–æ,
                    "consonants": —á–∏—Å–ª–æ,
                    "voiced_consonants": —á–∏—Å–ª–æ,
                    "voiceless_consonants": —á–∏—Å–ª–æ,
                    "hard_consonants": —á–∏—Å–ª–æ,
                    "soft_consonants": —á–∏—Å–ª–æ
                },
                "sound_letter_analysis": "–ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∑–≤—É–∫-–±—É–∫–≤–∞",
                "phonetic_features": ["–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å1", "–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å2"]
            }
            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.""",

            'synonyms': """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ª–µ–∫—Å–∏–∫–æ–ª–æ–≥–∏–∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –ù–∞–π–¥–∏ —Å–∏–Ω–æ–Ω–∏–º—ã, –∞–Ω—Ç–æ–Ω–∏–º—ã –∏ —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞. –û—Ç–≤–µ—á–∞–π –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {
                "word": "–∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ",
                "synonyms": ["—Å–∏–Ω–æ–Ω–∏–º1", "—Å–∏–Ω–æ–Ω–∏–º2", "—Å–∏–Ω–æ–Ω–∏–º3"],
                "antonyms": ["–∞–Ω—Ç–æ–Ω–∏–º1", "–∞–Ω—Ç–æ–Ω–∏–º2"],
                "related_words": ["—Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ1", "—Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ2"],
                "word_family": "—Å–ª–æ–≤–æ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –≥–Ω–µ–∑–¥–æ",
                "etymology": "–∫—Ä–∞—Ç–∫–∞—è —ç—Ç–∏–º–æ–ª–æ–≥–∏—è",
                "usage_examples": ["–ø—Ä–∏–º–µ—Ä1", "–ø—Ä–∏–º–µ—Ä2"],
                "stylistic_notes": "—Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–º–µ—Ç—ã"
            }
            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.""",

            'language_detection': """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é —è–∑—ã–∫–æ–≤. –û–ø—Ä–µ–¥–µ–ª–∏ —è–∑—ã–∫(–∏) —Ç–µ–∫—Å—Ç–∞ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∞–Ω–∞–ª–∏–∑. –û—Ç–≤–µ—á–∞–π –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {
                "detected_languages": [
                    {
                        "language": "–Ω–∞–∑–≤–∞–Ω–∏–µ —è–∑—ã–∫–∞",
                        "confidence": —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 100,
                        "code": "–∫–æ–¥ —è–∑—ã–∫–∞"
                    }
                ],
                "primary_language": "–æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫",
                "is_mixed": true/false,
                "language_features": ["–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å1", "–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å2"],
                "translation_hint": "–ø–æ–¥—Å–∫–∞–∑–∫–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"
            }
            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.""",

            'stylistics': """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç–∏–ª–∏—Å—Ç–∏–∫–µ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞. –û—Ç–≤–µ—á–∞–π –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {
                "style_type": "—Ç–∏–ø —Å—Ç–∏–ª—è",
                "stylistic_features": ["–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å1", "–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å2"],
                "tone": "—Ç–æ–Ω —Ç–µ–∫—Å—Ç–∞",
                "formality_level": "—É—Ä–æ–≤–µ–Ω—å —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏",
                "vocabulary_richness": "–±–æ–≥–∞—Ç—Å—Ç–≤–æ —Å–ª–æ–≤–∞—Ä—è",
                "sentence_variety": "—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π",
                "stylistic_errors": ["–æ—à–∏–±–∫–∞1", "–æ—à–∏–±–∫–∞2"],
                "improvement_suggestions": ["—Å–æ–≤–µ—Ç1", "—Å–æ–≤–µ—Ç2"],
                "overall_impression": "–æ–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ"
            }
            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.""",

            'etymology': """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —ç—Ç–∏–º–æ–ª–æ–≥–∏–∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –ò—Å—Å–ª–µ–¥—É–π –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞. –û—Ç–≤–µ—á–∞–π –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {
                "word": "–∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ",
                "origin": "–ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ",
                "historical_forms": ["—Ñ–æ—Ä–º–∞1", "—Ñ–æ—Ä–º–∞2"],
                "root": "–∫–æ—Ä–µ–Ω—å",
                "cognates": ["—Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ1", "—Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ2"],
                "borrowing_source": "–∏—Å—Ç–æ—á–Ω–∏–∫ –∑–∞–∏–º—Å—Ç–≤–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)",
                "meaning_evolution": "—ç–≤–æ–ª—é—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è",
                "interesting_facts": ["—Ñ–∞–∫—Ç1", "—Ñ–∞–∫—Ç2"]
            }
            –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."""
        }

        system_prompt = system_prompts.get(analysis_type, system_prompts['text_analysis'])

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º user_prompt –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
        user_prompts = {
            'text_analysis': f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç:

            "{text}"

            –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –ø–æ–ª–Ω—ã–π –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑.""",

            'morphology': f"""–°–¥–µ–ª–∞–π –ø–æ–ª–Ω—ã–π –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å–ª–æ–≤–∞: "{text}"

            –£–∫–∞–∂–∏ –≤—Å–µ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫—É—é —Ä–æ–ª—å.""",

            'phonetics': f"""–°–¥–µ–ª–∞–π —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞: "{text}"

            –£–∫–∞–∂–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é, —Å–ª–æ–≥–∏, —É–¥–∞—Ä–µ–Ω–∏–µ –∏ –∑–≤—É–∫–æ–≤–æ–π —Å–æ—Å—Ç–∞–≤.""",

            'synonyms': f"""–ù–∞–π–¥–∏ —Å–∏–Ω–æ–Ω–∏–º—ã, –∞–Ω—Ç–æ–Ω–∏–º—ã –∏ —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è: "{text}"

            –¢–∞–∫–∂–µ —É–∫–∞–∂–∏ —ç—Ç–∏–º–æ–ª–æ–≥–∏—é –∏ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.""",

            'language_detection': f"""–û–ø—Ä–µ–¥–µ–ª–∏ —è–∑—ã–∫(–∏) —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞:

            "{text}"

            –£–∫–∞–∂–∏ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö.""",

            'stylistics': f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞:

            "{text}"

            –£–∫–∞–∂–∏ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è.""",

            'etymology': f"""–ò—Å—Å–ª–µ–¥—É–π –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞: "{text}"

            –£–∫–∞–∂–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—ã –∏ —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞."""
        }

        user_prompt = user_prompts.get(analysis_type, user_prompts['text_analysis'])

        result = await self.make_gigachat_request(system_prompt, user_prompt)

        if result.get('success', False):
            response_text = result.get('response', '')
            return self._parse_analysis_response(response_text, analysis_type, text)
        else:
            return self._create_fallback_response(text, analysis_type, result.get('error', '–û—à–∏–±–∫–∞ API'))

    def _parse_analysis_response(self, response_text: str, analysis_type: str, original_text: str) -> Dict:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç GigaChat –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç
            clean_response = self._clean_json_response(response_text)

            # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
            try:
                parsed = json.loads(clean_response)
            except json.JSONDecodeError:
                # –ï—Å–ª–∏ –Ω–µ JSON, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç
                return {
                    'success': True,
                    'analysis_type': analysis_type,
                    'analysis': clean_response,
                    'original_text': original_text,
                    'source': 'gigachat_text'
                }

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
            formatted_response = self._format_analysis(parsed, analysis_type, original_text)

            return {
                'success': True,
                'analysis_type': analysis_type,
                'analysis': formatted_response,
                'parsed_data': parsed,
                'original_text': original_text,
                'source': 'gigachat'
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∞–Ω–∞–ª–∏–∑–∞ {analysis_type}: {e}")
            return self._create_fallback_response(original_text, analysis_type, "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞")

    def _format_analysis(self, parsed_data: Dict, analysis_type: str, original_text: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞"""

        if analysis_type == 'text_analysis':
            stats = parsed_data.get('statistics', {})
            return (
                    f"üìä <b>–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞:</b>\n\n"
                    f"<b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:</b>\n"
                    f"‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤: {stats.get('characters', 'N/A')}\n"
                    f"‚Ä¢ –°–ª–æ–≤: {stats.get('words', 'N/A')}\n"
                    f"‚Ä¢ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats.get('sentences', 'N/A')}\n"
                    f"‚Ä¢ –°—Ä. –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞: {stats.get('average_word_length', 'N/A')}\n"
                    f"‚Ä¢ –°—Ä. –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {stats.get('average_sentence_length', 'N/A')}\n\n"
                    f"<b>–°—Ç–∏–ª—å —è–∑—ã–∫–∞:</b> {parsed_data.get('language_style', 'N/A')}\n"
                    f"<b>–°–ª–æ–∂–Ω–æ—Å—Ç—å:</b> {parsed_data.get('complexity', 'N/A')}\n"
                    f"<b>–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å:</b> {parsed_data.get('readability_score', 'N/A')}/100\n"
                    f"<b>–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω:</b> {parsed_data.get('emotional_tone', 'N/A')}\n\n"
                    f"<b>–ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã:</b>\n" + "\n".join(
                [f"‚Ä¢ {theme}" for theme in parsed_data.get('key_themes', [])]) + "\n\n"
                                                                                 f"<b>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:</b>\n" + "\n".join(
                [f"‚Ä¢ {rec}" for rec in parsed_data.get('recommendations', [])])
            )

        elif analysis_type == 'morphology':
            features = parsed_data.get('grammatical_features', {})
            return (
                    f"üî§ <b>–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å–ª–æ–≤–∞ '{original_text}':</b>\n\n"
                    f"<b>–ß–∞—Å—Ç—å —Ä–µ—á–∏:</b> {parsed_data.get('part_of_speech', 'N/A')}\n"
                    f"<b>–ù–∞—á–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞:</b> {parsed_data.get('initial_form', 'N/A')}\n\n"
                    f"<b>–ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:</b>\n"
                    f"‚Ä¢ –ü–∞–¥–µ–∂: {features.get('case', 'N/A')}\n"
                    f"‚Ä¢ –ß–∏—Å–ª–æ: {features.get('number', 'N/A')}\n"
                    f"‚Ä¢ –†–æ–¥: {features.get('gender', 'N/A')}\n"
                    f"‚Ä¢ –õ–∏—Ü–æ: {features.get('person', 'N/A')}\n"
                    f"‚Ä¢ –í—Ä–µ–º—è: {features.get('tense', 'N/A')}\n"
                    f"‚Ä¢ –ù–∞–∫–ª–æ–Ω–µ–Ω–∏–µ: {features.get('mood', 'N/A')}\n"
                    f"‚Ä¢ –ó–∞–ª–æ–≥: {features.get('voice', 'N/A')}\n"
                    f"‚Ä¢ –í–∏–¥: {features.get('aspect', 'N/A')}\n\n"
                    f"<b>–ú–æ—Ä—Ñ–µ–º–Ω—ã–π —Ä–∞–∑–±–æ—Ä:</b>\n{parsed_data.get('morphological_analysis', 'N/A')}\n\n"
                    f"<b>–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è —Ä–æ–ª—å:</b> {parsed_data.get('syntactic_role', 'N/A')}\n\n"
                    f"<b>–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:</b>\n" + "\n".join(
                [f"‚Ä¢ {ex}" for ex in parsed_data.get('examples', [])])
            )

        elif analysis_type == 'phonetics':
            sound_analysis = parsed_data.get('sound_analysis', {})
            return (
                    f"üéµ <b>–§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞ '{original_text}':</b>\n\n"
                    f"<b>–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:</b> {parsed_data.get('transcription', 'N/A')}\n"
                    f"<b>–°–ª–æ–≥–∏:</b> {'-'.join(parsed_data.get('syllables', []))}\n"
                    f"<b>–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≥–æ–≤:</b> {parsed_data.get('syllable_count', 'N/A')}\n"
                    f"<b>–£–¥–∞—Ä–Ω—ã–π —Å–ª–æ–≥:</b> {parsed_data.get('stress_syllable', 'N/A')}\n\n"
                    f"<b>–ó–≤—É–∫–æ–≤–æ–π —Å–æ—Å—Ç–∞–≤:</b>\n"
                    f"‚Ä¢ –ì–ª–∞—Å–Ω—ã—Ö: {sound_analysis.get('vowels', 'N/A')}\n"
                    f"‚Ä¢ –°–æ–≥–ª–∞—Å–Ω—ã—Ö: {sound_analysis.get('consonants', 'N/A')}\n"
                    f"‚Ä¢ –ó–≤–æ–Ω–∫–∏—Ö —Å–æ–≥–ª–∞—Å–Ω—ã—Ö: {sound_analysis.get('voiced_consonants', 'N/A')}\n"
                    f"‚Ä¢ –ì–ª—É—Ö–∏—Ö —Å–æ–≥–ª–∞—Å–Ω—ã—Ö: {sound_analysis.get('voiceless_consonants', 'N/A')}\n"
                    f"‚Ä¢ –¢–≤—ë—Ä–¥—ã—Ö —Å–æ–≥–ª–∞—Å–Ω—ã—Ö: {sound_analysis.get('hard_consonants', 'N/A')}\n"
                    f"‚Ä¢ –ú—è–≥–∫–∏—Ö —Å–æ–≥–ª–∞—Å–Ω—ã—Ö: {sound_analysis.get('soft_consonants', 'N/A')}\n\n"
                    f"<b>–ó–≤—É–∫–æ-–±—É–∫–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:</b>\n{parsed_data.get('sound_letter_analysis', 'N/A')}\n\n"
                    f"<b>–§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:</b>\n" + "\n".join(
                [f"‚Ä¢ {feature}" for feature in parsed_data.get('phonetic_features', [])])
            )

        elif analysis_type == 'synonyms':
            return (
                    f"üìö <b>–õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞ '{original_text}':</b>\n\n"
                    f"<b>–°–∏–Ω–æ–Ω–∏–º—ã:</b>\n" + "\n".join([f"‚Ä¢ {syn}" for syn in parsed_data.get('synonyms', [])]) + "\n\n"
                                                                                                                 f"<b>–ê–Ω—Ç–æ–Ω–∏–º—ã:</b>\n" + "\n".join(
                [f"‚Ä¢ {ant}" for ant in parsed_data.get('antonyms', [])]) + "\n\n"
                                                                           f"<b>–†–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞:</b>\n" + "\n".join(
                [f"‚Ä¢ {rel}" for rel in parsed_data.get('related_words', [])]) + "\n\n"
                                                                                f"<b>–°–ª–æ–≤–æ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –≥–Ω–µ–∑–¥–æ:</b>\n{parsed_data.get('word_family', 'N/A')}\n\n"
                                                                                f"<b>–≠—Ç–∏–º–æ–ª–æ–≥–∏—è:</b>\n{parsed_data.get('etymology', 'N/A')}\n\n"
                                                                                f"<b>–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:</b>\n" + "\n".join(
                [f"‚Ä¢ {ex}" for ex in parsed_data.get('usage_examples', [])]) + "\n\n"
                                                                               f"<b>–°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–º–µ—Ç—ã:</b>\n{parsed_data.get('stylistic_notes', 'N/A')}"
            )

        elif analysis_type == 'language_detection':
            languages = parsed_data.get('detected_languages', [])
            lang_list = "\n".join([f"‚Ä¢ {lang.get('language')}: {lang.get('confidence')}%" for lang in languages])
            return (
                    f"üåç <b>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞:</b>\n\n"
                    f"<b>–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —è–∑—ã–∫–∏:</b>\n{lang_list}\n\n"
                    f"<b>–û—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫:</b> {parsed_data.get('primary_language', 'N/A')}\n"
                    f"<b>–°–º–µ—à–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:</b> {'–î–∞' if parsed_data.get('is_mixed', False) else '–ù–µ—Ç'}\n\n"
                    f"<b>–Ø–∑—ã–∫–æ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:</b>\n" + "\n".join(
                [f"‚Ä¢ {feature}" for feature in parsed_data.get('language_features', [])]) + "\n\n"
                                                                                            f"<b>–ü–æ–¥—Å–∫–∞–∑–∫–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞:</b>\n{parsed_data.get('translation_hint', 'N/A')}"
            )

        elif analysis_type == 'stylistics':
            return (
                    f"üé® <b>–°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞:</b>\n\n"
                    f"<b>–¢–∏–ø —Å—Ç–∏–ª—è:</b> {parsed_data.get('style_type', 'N/A')}\n"
                    f"<b>–¢–æ–Ω —Ç–µ–∫—Å—Ç–∞:</b> {parsed_data.get('tone', 'N/A')}\n"
                    f"<b>–£—Ä–æ–≤–µ–Ω—å —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏:</b> {parsed_data.get('formality_level', 'N/A')}\n"
                    f"<b>–ë–æ–≥–∞—Ç—Å—Ç–≤–æ —Å–ª–æ–≤–∞—Ä—è:</b> {parsed_data.get('vocabulary_richness', 'N/A')}\n"
                    f"<b>–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π:</b> {parsed_data.get('sentence_variety', 'N/A')}\n\n"
                    f"<b>–°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:</b>\n" + "\n".join(
                [f"‚Ä¢ {feature}" for feature in parsed_data.get('stylistic_features', [])]) + "\n\n"
                                                                                             f"<b>–°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏:</b>\n" + (
                        "\n".join(
                            [f"‚Ä¢ {error}" for error in parsed_data.get('stylistic_errors', [])]) if parsed_data.get(
                            'stylistic_errors') else "‚Ä¢ –ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ") + "\n\n"
                                                                          f"<b>–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:</b>\n" + "\n".join(
                [f"‚Ä¢ {suggestion}" for suggestion in parsed_data.get('improvement_suggestions', [])]) + "\n\n"
                                                                                                        f"<b>–û–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ:</b>\n{parsed_data.get('overall_impression', 'N/A')}"
            )

        elif analysis_type == 'etymology':
            return (
                    f"üìú <b>–≠—Ç–∏–º–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞ '{original_text}':</b>\n\n"
                    f"<b>–ü—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ:</b>\n{parsed_data.get('origin', 'N/A')}\n\n"
                    f"<b>–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—ã:</b>\n" + "\n".join(
                [f"‚Ä¢ {form}" for form in parsed_data.get('historical_forms', [])]) + "\n\n"
                                                                                     f"<b>–ö–æ—Ä–µ–Ω—å:</b> {parsed_data.get('root', 'N/A')}\n\n"
                                                                                     f"<b>–†–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞:</b>\n" + "\n".join(
                [f"‚Ä¢ {cognate}" for cognate in parsed_data.get('cognates', [])]) + "\n\n"
                                                                                   f"<b>–ò—Å—Ç–æ—á–Ω–∏–∫ –∑–∞–∏–º—Å—Ç–≤–æ–≤–∞–Ω–∏—è:</b> {parsed_data.get('borrowing_source', '–ù–µ –∑–∞–∏–º—Å—Ç–≤–æ–≤–∞–Ω–æ')}\n\n"
                                                                                   f"<b>–≠–≤–æ–ª—é—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è:</b>\n{parsed_data.get('meaning_evolution', 'N/A')}\n\n"
                                                                                   f"<b>–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Ñ–∞–∫—Ç—ã:</b>\n" + "\n".join(
                [f"‚Ä¢ {fact}" for fact in parsed_data.get('interesting_facts', [])])
            )

        else:
            # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º JSON –∫–∞–∫ —Ç–µ–∫—Å—Ç
            return f"<b>–ê–Ω–∞–ª–∏–∑ ({analysis_type}):</b>\n{json.dumps(parsed_data, ensure_ascii=False, indent=2)}"

    def _clean_json_response(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON"""
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)

        start = text.find('{')
        end = text.rfind('}')

        if start != -1 and end != -1 and end > start:
            return text[start:end + 1]

        return text.strip()

    def _create_fallback_response(self, text: str, analysis_type: str, error_msg: str) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        return {
            'success': False,
            'analysis_type': analysis_type,
            'analysis': f'–ò–ò –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {error_msg}',
            'original_text': text,
            'source': 'error'
        }


# ==================== –ö–õ–ê–°–° –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ì–†–ê–ú–ú–ê–¢–ò–ö–ò ====================

class GigaChatGrammarChecker(GigaChatBase):
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ GigaChat"""

    async def check_grammar(self, text: str) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é"""
        if not text.strip():
            return {
                'success': True,
                'ai_comment': '–¢–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π',
                'has_errors': False,
                'source': 'gigachat'
            }

        system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä—É—Å—Å–∫–æ–π –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –Ω–∞:

1. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø—Ä–æ–≤–µ—Ä—å –∑–∞–ø—è—Ç—ã–µ:
   - –ü–µ—Ä–µ–¥ —Å–æ—é–∑–∞–º–∏ "–∞", "–Ω–æ", "–¥–∞" (–≤ –∑–Ω–∞—á–µ–Ω–∏–∏ "–Ω–æ"), "–æ–¥–Ω–∞–∫–æ", "–∑–∞—Ç–æ" –≤ —Å–ª–æ–∂–Ω–æ—Å–æ—á–∏–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
   - –ü–µ—Ä–µ–¥ —Å–æ—é–∑–∞–º–∏ "—á—Ç–æ", "—á—Ç–æ–±—ã", "–∫–æ–≥–¥–∞", "–ø–æ—Ç–æ–º—É —á—Ç–æ", "—Ç–∞–∫ –∫–∞–∫", "–µ—Å–ª–∏" –≤ —Å–ª–æ–∂–Ω–æ–ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
   - –í —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏
   - –ü—Ä–∏ –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã—Ö —á–ª–µ–Ω–∞—Ö —Å —Å–æ—é–∑–∞–º–∏ "–∞", "–Ω–æ", "–∏", "–∏–ª–∏"

2. –ü—Ä–æ–≤–µ—Ä—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é:
   - –ó–∞–ø—è—Ç—ã–µ –≤ –ø—Ä–∏—á–∞—Å—Ç–Ω—ã—Ö –∏ –¥–µ–µ–ø—Ä–∏—á–∞—Å—Ç–Ω—ã—Ö –æ–±–æ—Ä–æ—Ç–∞—Ö
   - –¢–∏—Ä–µ –º–µ–∂–¥—É –ø–æ–¥–ª–µ–∂–∞—â–∏–º –∏ —Å–∫–∞–∑—É–µ–º—ã–º
   - –î–≤–æ–µ—Ç–æ—á–∏—è –ø—Ä–∏ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è—Ö –∏ –ø–æ—è—Å–Ω–µ–Ω–∏—è—Ö
   - –ö–∞–≤—ã—á–∫–∏ –≤ –ø—Ä—è–º–æ–π —Ä–µ—á–∏

3. –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏:
   - –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –ø–æ–¥–ª–µ–∂–∞—â–µ–≥–æ –∏ —Å–∫–∞–∑—É–µ–º–æ–≥–æ
   - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (–ø–∞–¥–µ–∂–∏ –ø–æ—Å–ª–µ –ø—Ä–µ–¥–ª–æ–≥–æ–≤ –∏ –≥–ª–∞–≥–æ–ª–æ–≤)
   - –í–∏–¥–æ-–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã –≥–ª–∞–≥–æ–ª–æ–≤

4. –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏

–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ: {
    "issues": [{
        "type": "—Ç–∏–ø –æ—à–∏–±–∫–∏ (–ø—É–Ω–∫—Ç—É–∞—Ü–∏—è/–≥—Ä–∞–º–º–∞—Ç–∏–∫–∞/—Å—Ç–∏–ª–∏—Å—Ç–∏–∫–∞)",
        "original": "—Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å –æ—à–∏–±–∫–æ–π", 
        "corrected": "–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç", 
        "explanation": "–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞",
        "severity": "—É—Ä–æ–≤–µ–Ω—å —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ (–Ω–∏–∑–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–≤—ã—Å–æ–∫–∏–π)"
    }], 
    "corrected_text": "–ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π", 
    "ai_comment": "–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞", 
    "issue_count": —á–∏—Å–ª–æ,
    "score": —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 100
}"""

        user_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞:

        "{text}"

        **–í–ù–ò–ú–ê–ù–ò–ï: –û–±—Ä–∞—Ç–∏ –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∑–∞–ø—è—Ç—ã–µ:**
        1. –ü–µ—Ä–µ–¥ —Å–æ—é–∑–∞–º–∏ "–∞", "–Ω–æ", "–æ–¥–Ω–∞–∫–æ", "–∑–∞—Ç–æ" - –≤—Å–µ–≥–¥–∞ —Å—Ç–∞–≤–∏—Ç—Å—è –∑–∞–ø—è—Ç–∞—è –≤ —Å–ª–æ–∂–Ω–æ—Å–æ—á–∏–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
        2. –ü–µ—Ä–µ–¥ "—á—Ç–æ", "—á—Ç–æ–±—ã", "–ø–æ—Ç–æ–º—É —á—Ç–æ", "—Ç–∞–∫ –∫–∞–∫", "–µ—Å–ª–∏", "–∫–æ–≥–¥–∞" - –≤ —Å–ª–æ–∂–Ω–æ–ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
        3. –ú–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏ —Å–ª–æ–∂–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        4. –ü—Ä–∏ –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã—Ö —á–ª–µ–Ω–∞—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è

        **–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∏:**
        - "–Ø —Ö–æ—Ç–µ–ª –ø–æ–µ—Ö–∞—Ç—å –≤ –æ—Ç–ø—É—Å–∫, –∞ –Ω–∞ —Ä–∞–±–æ—Ç–µ —Å–∫–∞–∑–∞–ª–∏..."
        - "–ú–∞–º–∞ —Å–∫–∞–∑–∞–ª–∞, —á—Ç–æ –ø—Ä–∏–¥—É—Ç –≥–æ—Å—Ç–∏"
        - "–û–Ω —É—Å—Ç–∞–ª, –ø–æ—ç—Ç–æ–º—É –ª–µ–≥ —Å–ø–∞—Ç—å"
        - "–Ø –∫—É–ø–∏–ª —Ö–ª–µ–±, –º–æ–ª–æ–∫–æ –∏ —Å—ã—Ä"

        –ù–∞–π–¥–∏ –í–°–ï –æ—à–∏–±–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ –∏ –∏—Å–ø—Ä–∞–≤—å –∏—Ö."""

        result = await self.make_gigachat_request(system_prompt, user_prompt)

        if result.get('success', False):
            response_text = result.get('response', '')
            return self._parse_grammar_response(response_text, text)
        else:
            return self._create_fallback_response(text, result.get('error', '–û—à–∏–±–∫–∞ API'))

    def _parse_grammar_response(self, response_text: str, original_text: str) -> Dict:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç GigaChat –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç
            clean_response = self._clean_json_response(response_text)
            parsed = json.loads(clean_response)

            issues = parsed.get('issues', [])
            corrected_text = parsed.get('corrected_text', original_text)
            ai_comment = parsed.get('ai_comment', '')
            issue_count = parsed.get('issue_count', len(issues))
            score = parsed.get('score', max(0, 100 - (issue_count * 5)))

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–∞—Ö
            issue_list = []
            correction_list = []
            explanation_list = []
            type_list = []
            severity_list = []

            for issue in issues:
                if isinstance(issue, dict):
                    issue_type = issue.get('type', '–≥—Ä–∞–º–º–∞—Ç–∏–∫–∞')
                    original = issue.get('original', '')
                    corrected = issue.get('corrected', '')
                    explanation = issue.get('explanation', '')
                    severity = issue.get('severity', '—Å—Ä–µ–¥–Ω–∏–π')

                    if original:
                        issue_list.append(original)
                        correction_list.append(corrected)
                        explanation_list.append(explanation)
                        type_list.append(issue_type)
                        severity_list.append(severity)

            return {
                'issues': issue_list,
                'corrections': correction_list,
                'explanations': explanation_list,
                'types': type_list,
                'severities': severity_list,
                'corrected_text': corrected_text,
                'ai_comment': ai_comment,
                'total_sentences': len(re.split(r'[.!?]+', original_text)),
                'total_chars': len(original_text),
                'issue_count': issue_count,
                'score': score,
                'has_issues': issue_count > 0,
                'success': True,
                'source': 'gigachat_grammar'
            }

        except json.JSONDecodeError:
            return self._create_text_response(response_text, original_text)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: {e}")
            return self._create_fallback_response(original_text, "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞")

    def _clean_json_response(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON"""
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)

        start = text.find('{')
        end = text.rfind('}')

        if start != -1 and end != -1 and end > start:
            return text[start:end + 1]

        return text.strip()

    def _create_text_response(self, response_text: str, original_text: str) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        return {
            'issues': [],
            'corrections': [],
            'explanations': [],
            'types': [],
            'severities': [],
            'corrected_text': original_text,
            'ai_comment': response_text[:300] if response_text else "–ò–ò –¥–∞–ª —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ",
            'total_sentences': len(re.split(r'[.!?]+', original_text)),
            'total_chars': len(original_text),
            'issue_count': 0,
            'score': 100,
            'has_issues': False,
            'success': True,
            'source': 'gigachat_text'
        }

    def _create_fallback_response(self, text: str, error_msg: str) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        return {
            'issues': [],
            'corrections': [],
            'explanations': [],
            'types': [],
            'severities': [],
            'corrected_text': text,
            'ai_comment': f'–ò–ò –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {error_msg}',
            'total_sentences': len(re.split(r'[.!?]+', text)),
            'total_chars': len(text),
            'issue_count': 0,
            'score': 0,
            'has_issues': False,
            'success': False,
            'source': 'error'
        }


# ==================== –ö–õ–ê–°–° –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –û–†–§–û–ì–†–ê–§–ò–ò ====================

class GigaChatSpellChecker(GigaChatBase):
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ —á–µ—Ä–µ–∑ GigaChat"""

    async def check_spelling(self, text: str) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é –∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É"""
        if not text.strip():
            return {
                'success': True,
                'ai_comment': '–¢–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π',
                'has_errors': False,
                'source': 'gigachat'
            }

        system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É. –ù–∞–π–¥–∏ –∏ –∏—Å–ø—Ä–∞–≤—å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∏ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ. 
        –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ: {
            "errors": [{"original": "—Å–ª–æ–≤–æ", "corrected": "–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", "explanation": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ"}], 
            "corrected_text": "–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç", 
            "ai_comment": "–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", 
            "error_count": —á–∏—Å–ª–æ,
            "accuracy_score": —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 100
        }"""

        user_prompt = f"""–ü—Ä–æ–≤–µ—Ä—å –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é –∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É —Ç–µ–∫—Å—Ç–∞: "{text}"
        –ï—Å–ª–∏ –æ—à–∏–±–æ–∫ –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ errors."""

        result = await self.make_gigachat_request(system_prompt, user_prompt)

        if result.get('success', False):
            response_text = result.get('response', '')
            return self._parse_spelling_response(response_text, text)
        else:
            return self._create_fallback_response(text, result.get('error', '–û—à–∏–±–∫–∞ API'))

    def _parse_spelling_response(self, response_text: str, original_text: str) -> Dict:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç GigaChat –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏"""
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç
            clean_response = self._clean_json_response(response_text)
            parsed = json.loads(clean_response)

            errors = parsed.get('errors', [])
            corrected_text = parsed.get('corrected_text', original_text)
            ai_comment = parsed.get('ai_comment', '')
            error_count = parsed.get('error_count', len(errors))
            accuracy_score = parsed.get('accuracy_score', max(0, 100 - (error_count * 10)))

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—à–∏–±–∫–∏
            error_list = []
            suggestion_list = []
            explanation_list = []

            for error in errors:
                if isinstance(error, dict):
                    original = error.get('original', '')
                    corrected = error.get('corrected', '')
                    explanation = error.get('explanation', '')

                    if original and corrected:
                        error_list.append(original)
                        suggestion_list.append(corrected)
                        explanation_list.append(explanation)

            return {
                'errors': error_list,
                'suggestions': suggestion_list,
                'explanations': explanation_list,
                'corrected_text': corrected_text,
                'ai_comment': ai_comment,
                'total_words': len(re.findall(r'\b\w+\b', original_text)),
                'error_words': error_count,
                'has_errors': error_count > 0,
                'accuracy_score': accuracy_score,
                'success': True,
                'source': 'gigachat_spelling'
            }

        except json.JSONDecodeError:
            return self._create_text_response(response_text, original_text)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return self._create_fallback_response(original_text, "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞")

    def _clean_json_response(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON"""
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)

        start = text.find('{')
        end = text.rfind('}')

        if start != -1 and end != -1 and end > start:
            return text[start:end + 1]

        return text.strip()

    def _create_text_response(self, response_text: str, original_text: str) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        return {
            'errors': [],
            'suggestions': [],
            'explanations': [],
            'corrected_text': original_text,
            'ai_comment': response_text[:300] if response_text else "–ò–ò –¥–∞–ª —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
            'total_words': len(re.findall(r'\b\w+\b', original_text)),
            'error_words': 0,
            'has_errors': False,
            'accuracy_score': 100,
            'success': True,
            'source': 'gigachat_text'
        }

    def _create_fallback_response(self, text: str, error_msg: str) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        return {
            'errors': [],
            'suggestions': [],
            'explanations': [],
            'corrected_text': text,
            'ai_comment': f'–ò–ò –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {error_msg}',
            'has_errors': False,
            'accuracy_score': 0,
            'success': False,
            'source': 'error'
        }


# ==================== –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–´–ô –ü–†–û–í–ï–†–Ø–õ–¨–©–ò–ö ====================

class CombinedAnalyzer:
    """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å GigaChat AI"""

    def __init__(self, gigachat_client_id: str = None, gigachat_client_secret: str = None):
        self.universal_analyzer = None
        self.grammar_checker = None
        self.spell_checker = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã GigaChat
        if gigachat_client_id and gigachat_client_secret:
            try:
                self.universal_analyzer = GigaChatUniversalAnalyzer(gigachat_client_id, gigachat_client_secret)
                self.grammar_checker = GigaChatGrammarChecker(gigachat_client_id, gigachat_client_secret)
                self.spell_checker = GigaChatSpellChecker(gigachat_client_id, gigachat_client_secret)
                logger.info("‚úÖ –í—Å–µ –ò–ò –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ GigaChat –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤: {e}")

        # –õ–æ–∫–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –æ—à–∏–±–æ–∫
        self.common_errors = {
            '–∑–¥—Ä–∞—Å—Ç–≤—É–π—Ç–µ': ('–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ', '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è'),
            '–∑–¥–µ–ª–∞—Ç—å': ('—Å–¥–µ–ª–∞—Ç—å', '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø—Ä–∏—Å—Ç–∞–≤–∫–∞'),
            '–ø—Ä–∏–¥—Ç–∏': ('–ø—Ä–∏–π—Ç–∏', '–£—Å—Ç–∞—Ä–µ–≤—à–∞—è —Ñ–æ—Ä–º–∞ –≥–ª–∞–≥–æ–ª–∞'),
            '–∏—Ö–Ω–∏–π': ('–∏—Ö', '–ü—Ä–æ—Å—Ç–æ—Ä–µ—á–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ'),
            '–ª–æ–∂–∏—Ç—å': ('–∫–ª–∞—Å—Ç—å', '–ì–ª–∞–≥–æ–ª "–ª–æ–∂–∏—Ç—å" –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ —Å –ø—Ä–∏—Å—Ç–∞–≤–∫–∞–º–∏'),
            '–æ–¥–µ–ª': ('–Ω–∞–¥–µ–ª', '–ü—É—Ç–∞–Ω–∏—Ü–∞ —Å –≥–ª–∞–≥–æ–ª–∞–º–∏ –æ–¥–µ–≤–∞—Ç—å/–Ω–∞–¥–µ–≤–∞—Ç—å'),
            '—Å–∏–º–ø–æ—Ç–∏—á–Ω—ã–π': ('—Å–∏–º–ø–∞—Ç–∏—á–Ω—ã–π', '–û–ø–µ—á–∞—Ç–∫–∞ –≤ —Å–ª–æ–≤–µ'),
            '—ç–∫—Å—Ç—Ä–∏–º–∞–ª—å–Ω—ã–π': ('—ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π', '–û–ø–µ—á–∞—Ç–∫–∞ "–∏" –≤–º–µ—Å—Ç–æ "–µ"'),
            '–∞–≥–µ–Ω—Å—Ç–≤–æ': ('–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ', '–û—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞'),
            '—Å–¥–µ—Å—å': ('–∑–¥–µ—Å—å', '–ü—Ä–∞–≤–∏–ª—å–Ω–æ —á–µ—Ä–µ–∑ "–∑–¥–µ"'),
            '—á–µ—Ä–µ–∑-—á—é—Ä': ('—á–µ—Ä–µ—Å—á—É—Ä', '–°–ª–∏—Ç–Ω–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ'),
            '–≤–æ–æ–±—â–µ–º': ('–≤ –æ–±—â–µ–º', '–†–∞–∑–¥–µ–ª—å–Ω–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ'),
        }

    async def analyze(self, text: str, analysis_type: str) -> Dict:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not self.universal_analyzer:
            return self._create_local_fallback(text, analysis_type, "GigaChat API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")

        try:
            return await self.universal_analyzer.analyze_text(text, analysis_type)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ò–ò –∞–Ω–∞–ª–∏–∑–∞ {analysis_type}: {e}")
            return self._create_local_fallback(text, analysis_type, str(e))

    async def check_grammar(self, text: str) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
        if not self.grammar_checker:
            return self._create_grammar_fallback(text)

        try:
            return await self.grammar_checker.check_grammar(text)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ò–ò –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: {e}")
            return self._create_grammar_fallback(text)

    async def check_spelling(self, text: str) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏"""
        if not self.spell_checker:
            return self._create_spelling_fallback(text)

        try:
            return await self.spell_checker.check_spelling(text)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ò–ò –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏: {e}")
            return self._create_spelling_fallback(text)

    def _create_local_fallback(self, text: str, analysis_type: str, error_msg: str) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        return {
            'success': False,
            'analysis_type': analysis_type,
            'analysis': f'–ò–ò –∞–Ω–∞–ª–∏–∑ ({analysis_type}) –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {error_msg}\n\n–ò—Å–ø–æ–ª—å–∑—É—é –ª–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑...',
            'original_text': text,
            'source': 'local_fallback'
        }

    def _create_grammar_fallback(self, text: str) -> Dict:
        """–õ–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
        issues = []
        corrections = []
        explanations = []
        types = []
        severities = []

        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if '  ' in text:
            issues.append('–¥–≤–æ–π–Ω–æ–π –ø—Ä–æ–±–µ–ª')
            corrections.append('–æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª')
            explanations.append('–£–±–µ—Ä–∏—Ç–µ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã')
            types.append('–ø—É–Ω–∫—Ç—É–∞—Ü–∏—è')
            severities.append('–Ω–∏–∑–∫–∏–π')

        if re.search(r'[–∞-—è—ë]\s+–∞\s+[–∞-—è—ë]', text, re.IGNORECASE):
            issues.append('–ø—Ä–æ–ø—É—â–µ–Ω–∞ –∑–∞–ø—è—Ç–∞—è –ø–µ—Ä–µ–¥ —Å–æ—é–∑–æ–º "–∞"')
            corrections.append('–¥–æ–±–∞–≤–∏—Ç—å –∑–∞–ø—è—Ç—É—é –ø–µ—Ä–µ–¥ "–∞"')
            explanations.append('–í —Å–ª–æ–∂–Ω–æ—Å–æ—á–∏–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –ø–µ—Ä–µ–¥ —Å–æ—é–∑–æ–º "–∞" –≤—Å–µ–≥–¥–∞ —Å—Ç–∞–≤–∏—Ç—Å—è –∑–∞–ø—è—Ç–∞—è')
            types.append('–ø—É–Ω–∫—Ç—É–∞—Ü–∏—è')
            severities.append('–≤—ã—Å–æ–∫–∏–π')

        if re.search(r'[–∞-—è—ë]\s+—á—Ç–æ\s+[–∞-—è—ë]', text, re.IGNORECASE):
            issues.append('–ø—Ä–æ–ø—É—â–µ–Ω–∞ –∑–∞–ø—è—Ç–∞—è –ø–µ—Ä–µ–¥ —Å–æ—é–∑–æ–º "—á—Ç–æ"')
            corrections.append('–¥–æ–±–∞–≤–∏—Ç—å –∑–∞–ø—è—Ç—É—é –ø–µ—Ä–µ–¥ "—á—Ç–æ"')
            explanations.append('–í —Å–ª–æ–∂–Ω–æ–ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –ø–µ—Ä–µ–¥ —Å–æ—é–∑–æ–º "—á—Ç–æ" —Å—Ç–∞–≤–∏—Ç—Å—è –∑–∞–ø—è—Ç–∞—è')
            types.append('–ø—É–Ω–∫—Ç—É–∞—Ü–∏—è')
            severities.append('–≤—ã—Å–æ–∫–∏–π')

        return {
            'issues': issues,
            'corrections': corrections,
            'explanations': explanations,
            'types': types,
            'severities': severities,
            'corrected_text': text,
            'ai_comment': '–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏',
            'total_sentences': len(re.split(r'[.!?]+', text)),
            'total_chars': len(text),
            'issue_count': len(issues),
            'score': 100 if not issues else 80,
            'has_issues': len(issues) > 0,
            'success': True,
            'source': 'local'
        }

    def _create_spelling_fallback(self, text: str) -> Dict:
        """–õ–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏"""
        errors = []
        suggestions = []
        explanations = []

        words = re.findall(r'\b[–∞-—è—ë–ê-–Ø–Å]+\b', text)

        for word in words:
            word_lower = word.lower()
            if word_lower in self.common_errors:
                correction, explanation = self.common_errors[word_lower]
                errors.append(word)
                suggestions.append(correction)
                explanations.append(explanation)

        return {
            'errors': errors,
            'suggestions': suggestions,
            'explanations': explanations,
            'corrected_text': text,
            'ai_comment': '–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏',
            'total_words': len(words),
            'error_words': len(errors),
            'has_errors': len(errors) > 0,
            'accuracy_score': 100 if not errors else 80,
            'success': True,
            'source': 'local'
        }

    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        if self.universal_analyzer:
            await self.universal_analyzer.close()
        if self.grammar_checker:
            await self.grammar_checker.close()
        if self.spell_checker:
            await self.spell_checker.close()


# ==================== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê ====================

analyzer = CombinedAnalyzer(
    gigachat_client_id=GIGACHAT_CLIENT_ID,
    gigachat_client_secret=GIGACHAT_CLIENT_SECRET
)


# ==================== –û–°–ù–û–í–ù–û–ô –ö–û–î –ë–û–¢–ê ====================

def get_main_keyboard():
    keyboard = [
        [KeyboardButton("üìä –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ (–ò–ò)")],
        [KeyboardButton("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ (–ò–ò)")],
        [KeyboardButton("üéµ –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–ò–ò)")],
        [KeyboardButton("üî§ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è (–ò–ò)")],
        [KeyboardButton("üìö –°–∏–Ω–æ–Ω–∏–º—ã (–ò–ò)")],
        [KeyboardButton("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ (–ò–ò)")],
        [KeyboardButton("üåç –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —è–∑—ã–∫ (–ò–ò)")],
        [KeyboardButton("üé® –°—Ç–∏–ª–∏—Å—Ç–∏–∫–∞ (–ò–ò)")],
        [KeyboardButton("üìú –≠—Ç–∏–º–æ–ª–æ–≥–∏—è (–ò–ò)")],
        [KeyboardButton("‚ùì –ü–æ–º–æ—â—å")]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True, one_time_keyboard=False)


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user

    gigachat_status = "‚úÖ GigaChat API –¥–æ—Å—Ç—É–ø–µ–Ω" if GIGACHAT_CLIENT_ID and GIGACHAT_CLIENT_SECRET else "‚ö†Ô∏è GigaChat API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    await update.message.reply_text(
        f"ü§ñ <b>–ü—Ä–∏–≤–µ—Ç, {user.first_name}! –Ø –±–æ—Ç-–ª–∏–Ω–≥–≤–∏—Å—Ç —Å –ò–ò</b>\n\n"
        "‚ú® <b>–í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —á–µ—Ä–µ–∑ GigaChat AI:</b>\n"
        "‚Ä¢ üìä <b>–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞</b> - –ø–æ–ª–Ω—ã–π –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑\n"
        "‚Ä¢ ü§ñ <b>–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏</b> - –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è –∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å\n"
        "‚Ä¢ üéµ <b>–§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑</b> - –∑–≤—É–∫–∏ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è\n"
        "‚Ä¢ üî§ <b>–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è</b> - –ø–æ–ª–Ω—ã–π —Ä–∞–∑–±–æ—Ä —Å–ª–æ–≤–∞\n"
        "‚Ä¢ üìö <b>–°–∏–Ω–æ–Ω–∏–º—ã</b> - —Å–∏–Ω–æ–Ω–∏–º—ã, –∞–Ω—Ç–æ–Ω–∏–º—ã, —ç—Ç–∏–º–æ–ª–æ–≥–∏—è\n"
        "‚Ä¢ üîç <b>–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏</b> - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫\n"
        "‚Ä¢ üåç <b>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞</b> - –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n"
        "‚Ä¢ üé® <b>–°—Ç–∏–ª–∏—Å—Ç–∏–∫–∞</b> - –∞–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è –∏ —Ç–æ–Ω–∞\n"
        "‚Ä¢ üìú <b>–≠—Ç–∏–º–æ–ª–æ–≥–∏—è</b> - –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Å–ª–æ–≤\n\n"
        f"{gigachat_status}\n\n"
        "<b>–ö–æ–º–∞–Ω–¥—ã:</b>\n"
        "/test - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏\n"
        "/help - –°–ø—Ä–∞–≤–∫–∞\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é –∏–∑ –º–µ–Ω—é –Ω–∏–∂–µ:",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 0


async def text_analysis_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞"""
    await update.message.reply_text(
        "üìä <b>–ü–æ–ª–Ω—ã–π –ò–ò –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:\n\n"
        "<i>GigaChat AI –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:</i>\n"
        "‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–µ–∫—Å—Ç–∞ (—Å–ª–æ–≤–∞, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)\n"
        "‚Ä¢ –°—Ç–∏–ª—å –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å —è–∑—ã–∫–∞\n"
        "‚Ä¢ –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω\n"
        "‚Ä¢ –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã\n"
        "‚Ä¢ –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n"
        "<b>–ü—Ä–∏–º–µ—Ä:</b>\n"
        "<code>–í –ª–µ—Å—É —Ä–æ–¥–∏–ª–∞—Å—å —ë–ª–æ—á–∫–∞, –≤ –ª–µ—Å—É –æ–Ω–∞ —Ä–æ—Å–ª–∞.</code>",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 1


async def process_text_analysis(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞"""
    text = update.message.text

    if not text.strip():
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
                                        reply_markup=get_main_keyboard())
        return 1

    status_msg = await update.message.reply_text(
        "ü§ñ <i>–ò–ò –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç...</i>\n<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥</i>",
        parse_mode='HTML'
    )

    try:
        result = await analyzer.analyze(text, 'text_analysis')

        await context.bot.delete_message(
            chat_id=update.effective_chat.id,
            message_id=status_msg.message_id
        )

        if result.get('success', False):
            response = result['analysis']
        else:
            response = result.get('analysis', '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑')

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–∞: {e}")

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=status_msg.message_id
            )
        except:
            pass

        response = (
            "‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–∞</b>\n\n"
            "<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ—É–Ω–∫—Ü–∏—é.</i>"
        )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    return 0


async def morphology_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    await update.message.reply_text(
        "üî§ <b>–ò–ò –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å–ª–æ–≤–∞</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:\n\n"
        "<i>GigaChat AI –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:</i>\n"
        "‚Ä¢ –ß–∞—Å—Ç—å —Ä–µ—á–∏\n"
        "‚Ä¢ –í—Å–µ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n"
        "‚Ä¢ –ù–∞—á–∞–ª—å–Ω—É—é —Ñ–æ—Ä–º—É\n"
        "‚Ä¢ –ú–æ—Ä—Ñ–µ–º–Ω—ã–π —Å–æ—Å—Ç–∞–≤\n"
        "‚Ä¢ –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫—É—é —Ä–æ–ª—å\n"
        "‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n\n"
        "<b>–ü—Ä–∏–º–µ—Ä—ã:</b>\n"
        "<code>–±–µ–≥—É—â–∏–π</code>\n"
        "<code>–ø—Ä–µ–∫—Ä–∞—Å–Ω—ã–π</code>\n"
        "<code>—á–∏—Ç–∞–ª–∏</code>",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 4


async def process_morphology(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    text = update.message.text.strip()

    if not text:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ",
                                        reply_markup=get_main_keyboard())
        return 4

    status_msg = await update.message.reply_text(
        "ü§ñ <i>–ò–ò –¥–µ–ª–∞–µ—Ç –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä...</i>\n<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥</i>",
        parse_mode='HTML'
    )

    try:
        result = await analyzer.analyze(text, 'morphology')

        await context.bot.delete_message(
            chat_id=update.effective_chat.id,
            message_id=status_msg.message_id
        )

        if result.get('success', False):
            response = result['analysis']
        else:
            response = result.get('analysis', '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑')

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ: {e}")

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=status_msg.message_id
            )
        except:
            pass

        response = (
            "‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ</b>\n\n"
            "<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ—É–Ω–∫—Ü–∏—é.</i>"
        )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    return 0


async def phonetics_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    await update.message.reply_text(
        "üéµ <b>–ò–ò —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:\n\n"
        "<i>GigaChat AI –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:</i>\n"
        "‚Ä¢ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é\n"
        "‚Ä¢ –°–ª–æ–≥–∏ –∏ —É–¥–∞—Ä–µ–Ω–∏–µ\n"
        "‚Ä¢ –ó–≤—É–∫–æ–≤–æ–π —Å–æ—Å—Ç–∞–≤\n"
        "‚Ä¢ –ó–≤–æ–Ω–∫–∏–µ/–≥–ª—É—Ö–∏–µ —Å–æ–≥–ª–∞—Å–Ω—ã–µ\n"
        "‚Ä¢ –¢–≤—ë—Ä–¥—ã–µ/–º—è–≥–∫–∏–µ —Å–æ–≥–ª–∞—Å–Ω—ã–µ\n"
        "‚Ä¢ –ó–≤—É–∫–æ-–±—É–∫–≤–µ–Ω–Ω—ã–π —Ä–∞–∑–±–æ—Ä\n\n"
        "<b>–ü—Ä–∏–º–µ—Ä—ã:</b>\n"
        "<code>—è–±–ª–æ–∫–æ</code>\n"
        "<code>—Å–æ–ª–Ω—Ü–µ</code>\n"
        "<code>—Å—á–∞—Å—Ç—å–µ</code>",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 3


async def process_phonetics(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    text = update.message.text.strip()

    if not text:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ",
                                        reply_markup=get_main_keyboard())
        return 3

    status_msg = await update.message.reply_text(
        "ü§ñ <i>–ò–ò –¥–µ–ª–∞–µ—Ç —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑...</i>\n<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥</i>",
        parse_mode='HTML'
    )

    try:
        result = await analyzer.analyze(text, 'phonetics')

        await context.bot.delete_message(
            chat_id=update.effective_chat.id,
            message_id=status_msg.message_id
        )

        if result.get('success', False):
            response = result['analysis']
        else:
            response = result.get('analysis', '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑')

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ: {e}")

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=status_msg.message_id
            )
        except:
            pass

        response = (
            "‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ</b>\n\n"
            "<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ—É–Ω–∫—Ü–∏—é.</i>"
        )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    return 0


async def synonyms_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤"""
    await update.message.reply_text(
        "üìö <b>–ò–ò –ª–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ –∞–Ω—Ç–æ–Ω–∏–º–æ–≤:\n\n"
        "<i>GigaChat AI –Ω–∞–π–¥—ë—Ç:</i>\n"
        "‚Ä¢ –°–∏–Ω–æ–Ω–∏–º—ã\n"
        "‚Ä¢ –ê–Ω—Ç–æ–Ω–∏–º—ã\n"
        "‚Ä¢ –†–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞\n"
        "‚Ä¢ –≠—Ç–∏–º–æ–ª–æ–≥–∏—é\n"
        "‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n"
        "‚Ä¢ –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–º–µ—Ç—ã\n\n"
        "<b>–ü—Ä–∏–º–µ—Ä—ã:</b>\n"
        "<code>–∫—Ä–∞—Å–∏–≤—ã–π</code>\n"
        "<code>–±—ã—Å—Ç—Ä–æ</code>\n"
        "<code>–¥–æ–±—Ä—ã–π</code>",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 7


async def process_synonyms(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤"""
    text = update.message.text.strip()

    if not text:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ",
                                        reply_markup=get_main_keyboard())
        return 7

    status_msg = await update.message.reply_text(
        "ü§ñ <i>–ò–ò –∏—â–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –∞–Ω—Ç–æ–Ω–∏–º—ã...</i>\n<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥</i>",
        parse_mode='HTML'
    )

    try:
        result = await analyzer.analyze(text, 'synonyms')

        await context.bot.delete_message(
            chat_id=update.effective_chat.id,
            message_id=status_msg.message_id
        )

        if result.get('success', False):
            response = result['analysis']
        else:
            response = result.get('analysis', '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑')

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤: {e}")

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=status_msg.message_id
            )
        except:
            pass

        response = (
            "‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤</b>\n\n"
            "<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ—É–Ω–∫—Ü–∏—é.</i>"
        )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    return 0


async def language_detection_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞"""
    await update.message.reply_text(
        "üåç <b>–ò–ò –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞:\n\n"
        "<i>GigaChat AI –æ–ø—Ä–µ–¥–µ–ª–∏—Ç:</i>\n"
        "‚Ä¢ –í—Å–µ —è–∑—ã–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ\n"
        "‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö\n"
        "‚Ä¢ –û—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫\n"
        "‚Ä¢ –Ø–∑—ã–∫–æ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏\n"
        "‚Ä¢ –ü–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞\n\n"
        "<b>–ü—Ä–∏–º–µ—Ä—ã:</b>\n"
        "<code>Hello world</code>\n"
        "<code>Bonjour tout le monde</code>\n"
        "<code>Hola mundo</code>",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 9


async def process_language_detection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞"""
    text = update.message.text.strip()

    if not text:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç",
                                        reply_markup=get_main_keyboard())
        return 9

    status_msg = await update.message.reply_text(
        "ü§ñ <i>–ò–ò –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫...</i>\n<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥</i>",
        parse_mode='HTML'
    )

    try:
        result = await analyzer.analyze(text, 'language_detection')

        await context.bot.delete_message(
            chat_id=update.effective_chat.id,
            message_id=status_msg.message_id
        )

        if result.get('success', False):
            response = result['analysis']
        else:
            response = result.get('analysis', '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑')

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —è–∑—ã–∫–∞: {e}")

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=status_msg.message_id
            )
        except:
            pass

        response = (
            "‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —è–∑—ã–∫–∞</b>\n\n"
            "<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ—É–Ω–∫—Ü–∏—é.</i>"
        )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    return 0


async def stylistics_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    await update.message.reply_text(
        "üé® <b>–ò–ò —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:\n\n"
        "<i>GigaChat AI –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:</i>\n"
        "‚Ä¢ –¢–∏–ø —Å—Ç–∏–ª—è\n"
        "‚Ä¢ –¢–æ–Ω —Ç–µ–∫—Å—Ç–∞\n"
        "‚Ä¢ –£—Ä–æ–≤–µ–Ω—å —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏\n"
        "‚Ä¢ –ë–æ–≥–∞—Ç—Å—Ç–≤–æ —Å–ª–æ–≤–∞—Ä—è\n"
        "‚Ä¢ –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏\n"
        "‚Ä¢ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é\n\n"
        "<b>–ü—Ä–∏–º–µ—Ä:</b>\n"
        "<code>–ù—É —ç—Ç–æ —Ç–∏–ø–∞ –≤ –æ–±—â–µ–º –∫–æ—Ä–æ—á–µ —è –ø–æ—à–µ–ª</code>",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 10


async def process_stylistics(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    text = update.message.text.strip()

    if not text:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç",
                                        reply_markup=get_main_keyboard())
        return 10

    status_msg = await update.message.reply_text(
        "ü§ñ <i>–ò–ò –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∏–ª–∏—Å—Ç–∏–∫—É...</i>\n<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥</i>",
        parse_mode='HTML'
    )

    try:
        result = await analyzer.analyze(text, 'stylistics')

        await context.bot.delete_message(
            chat_id=update.effective_chat.id,
            message_id=status_msg.message_id
        )

        if result.get('success', False):
            response = result['analysis']
        else:
            response = result.get('analysis', '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑')

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ: {e}")

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=status_msg.message_id
            )
        except:
            pass

        response = (
            "‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ</b>\n\n"
            "<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ—É–Ω–∫—Ü–∏—é.</i>"
        )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    return 0


async def etymology_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —ç—Ç–∏–º–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    await update.message.reply_text(
        "üìú <b>–ò–ò —ç—Ç–∏–º–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—è:\n\n"
        "<i>GigaChat AI –∏—Å—Å–ª–µ–¥–æ–≤–∞–µ—Ç:</i>\n"
        "‚Ä¢ –ü—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞\n"
        "‚Ä¢ –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—ã\n"
        "‚Ä¢ –ö–æ—Ä–µ–Ω—å —Å–ª–æ–≤–∞\n"
        "‚Ä¢ –†–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞\n"
        "‚Ä¢ –≠–≤–æ–ª—é—Ü–∏—é –∑–Ω–∞—á–µ–Ω–∏—è\n"
        "‚Ä¢ –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Ñ–∞–∫—Ç—ã\n\n"
        "<b>–ü—Ä–∏–º–µ—Ä—ã:</b>\n"
        "<code>–∫–æ–º–ø—å—é—Ç–µ—Ä</code>\n"
        "<code>—Å–ø—É—Ç–Ω–∏–∫</code>\n"
        "<code>–º–µ–¥–≤–µ–¥—å</code>",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 11


async def process_etymology(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —ç—Ç–∏–º–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    text = update.message.text.strip()

    if not text:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–ª–æ–≤–æ",
                                        reply_markup=get_main_keyboard())
        return 11

    status_msg = await update.message.reply_text(
        "ü§ñ <i>–ò–ò –∏—Å—Å–ª–µ–¥—É–µ—Ç —ç—Ç–∏–º–æ–ª–æ–≥–∏—é...</i>\n<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥</i>",
        parse_mode='HTML'
    )

    try:
        result = await analyzer.analyze(text, 'etymology')

        await context.bot.delete_message(
            chat_id=update.effective_chat.id,
            message_id=status_msg.message_id
        )

        if result.get('success', False):
            response = result['analysis']
        else:
            response = result.get('analysis', '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑')

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç—Ç–∏–º–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ: {e}")

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=status_msg.message_id
            )
        except:
            pass

        response = (
            "‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —ç—Ç–∏–º–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ</b>\n\n"
            "<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ—É–Ω–∫—Ü–∏—é.</i>"
        )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    return 0


# ==================== –°–£–©–ï–°–¢–í–£–Æ–©–ò–ï –§–£–ù–ö–¶–ò–ò (–≥—Ä–∞–º–º–∞—Ç–∏–∫–∞ –∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—è) ====================

async def grammar_check_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
    gigachat_status = " (—Å GigaChat AI)" if GIGACHAT_CLIENT_ID and GIGACHAT_CLIENT_SECRET else " (–ª–æ–∫–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)"

    await update.message.reply_text(
        f"ü§ñ <b>–ò–ò –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏{gigachat_status}</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:\n\n"
        "<i>–ò—Å–ø–æ–ª—å–∑—É—é GigaChat AI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:</i>\n"
        "‚Ä¢ –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è\n"
        "‚Ä¢ –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö\n"
        "‚Ä¢ –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n"
        "‚Ä¢ –õ–æ–≥–∏–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n\n"
        "<b>–ü—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞:</b>\n"
        "<code>–Ø –ø–æ—à–µ–ª –≤ –º–∞–≥–∞–∑–∏–Ω –∫—É–ø–∏–ª —Ö–ª–µ–± –º–æ–ª–æ–∫–æ –∏ —Å—ã—Ä</code>\n"
        "<code>–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ —á—Ç–æ –±—ã–ª–æ –ø–æ–∑–¥–Ω–æ –æ–Ω –ø—Ä–æ–¥–æ–ª–∂–∞–ª —Ä–∞–±–æ—Ç–∞—Ç—å.</code>\n"
        "<code>–ú–∞–º–∞ —Å–∫–∞–∑–∞–ª–∞ —á—Ç–æ–±—ã —è —É–±—Ä–∞–ª –∫–æ–º–Ω–∞—Ç—É –ø–æ—Ç–æ–º—É —á—Ç–æ –ø—Ä–∏–¥—É—Ç –≥–æ—Å—Ç–∏.</code>",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 2


async def process_grammar_check(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"""
    text = update.message.text

    if not text.strip():
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏",
                                        reply_markup=get_main_keyboard())
        return 2

    status_msg = await update.message.reply_text(
        "ü§ñ <i>–ò–ò –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≥—Ä–∞–º–º–∞—Ç–∏–∫—É...</i>\n<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥</i>",
        parse_mode='HTML'
    )

    try:
        result = await analyzer.check_grammar(text)

        await context.bot.delete_message(
            chat_id=update.effective_chat.id,
            message_id=status_msg.message_id
        )

        if result.get('success', False):
            if not result.get('has_issues', False):
                response = (
                    f"‚úÖ <b>–ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!</b>\n\n"
                    f"üìä <b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:</b>\n"
                    f"‚Ä¢ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {result['total_sentences']}\n"
                    f"‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤: {result['total_chars']}\n"
                    f"‚Ä¢ –û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ\n"
                    f"‚Ä¢ –û—Ü–µ–Ω–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: {result.get('score', 100)}/100\n"
                    f"‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫: {result.get('source', 'unknown')}\n\n"
                )

                ai_comment = result.get('ai_comment', '')
                if ai_comment and '–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞' not in ai_comment.lower():
                    response += f"üí° <b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ò–ò:</b>\n{ai_comment}\n\n"

                response += "<i>–û—Ç–ª–∏—á–Ω–∞—è –≥—Ä–∞–º–º–∞—Ç–∏–∫–∞! üëè</i>"

            else:
                response = f"‚ö†Ô∏è <b>–ù–∞–π–¥–µ–Ω–æ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º: {result['issue_count']}</b>\n\n"

                if result['issues']:
                    response += "<b>–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:</b>\n"
                    for i, (issue, correction, explanation, issue_type, severity) in enumerate(
                            zip(result['issues'], result['corrections'], result['explanations'],
                                result['types'], result['severities']), 1):
                        severity_icon = "üî¥" if severity == '–≤—ã—Å–æ–∫–∏–π' else "üü°" if severity == '—Å—Ä–µ–¥–Ω–∏–π' else "üü¢"
                        type_icon = "üìù" if '–ø—É–Ω–∫—Ç—É–∞—Ü–∏—è' in issue_type else "üî§" if '–≥—Ä–∞–º–º–∞—Ç–∏–∫–∞' in issue_type else "üí°"

                        response += f"{i}. {severity_icon}{type_icon} <b>{issue_type.upper()}</b>\n"
                        response += f"   <code>{issue}</code> ‚Üí <b>{correction}</b>\n"
                        response += f"   <i>{explanation}</i>\n\n"

                response += f"üìù <b>–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:</b>\n"
                response += f"<pre>{result['corrected_text']}</pre>\n\n"

                response += f"üìä <b>–î–µ—Ç–∞–ª–∏:</b>\n"
                response += f"‚Ä¢ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {result['total_sentences']}\n"
                response += f"‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤: {result['total_chars']}\n"
                response += f"‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {result['issue_count']}\n"
                response += f"‚Ä¢ –û—Ü–µ–Ω–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: {result.get('score', 0)}/100\n"
                response += f"‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫: {result.get('source', 'unknown')}\n\n"

                ai_comment = result.get('ai_comment', '')
                if ai_comment and '–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞' not in ai_comment.lower():
                    response += f"üí° <b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ò–ò:</b>\n{ai_comment}\n\n"

                response += "<i>ü§ñ –ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —Å –ø–æ–º–æ—â—å—é GigaChat AI</i>"
        else:
            ai_comment = result.get('ai_comment', '–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏')
            response = (
                f"‚ö†Ô∏è <b>–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å</b>\n\n"
                f"{ai_comment}"
            )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: {e}")

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=status_msg.message_id
            )
        except:
            pass

        response = (
            "‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏</b>\n\n"
            "<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ—É–Ω–∫—Ü–∏—é.</i>"
        )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    return 0


async def spell_check_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏"""
    await update.message.reply_text(
        "üîç <b>–ò–ò –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏</b>\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:\n\n"
        "<i>–ò—Å–ø–æ–ª—å–∑—É—é GigaChat AI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:</i>\n"
        "‚Ä¢ –û—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏\n"
        "‚Ä¢ –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏\n"
        "‚Ä¢ –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n"
        "<b>–ü—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞:</b>\n"
        "<code>–ó–¥—Ä–∞—Å—Ç–≤—É–π—Ç–µ, –∫–∞–∫ –≤–∞—à–∏ –¥–µ–ª–∞?</code>\n"
        "<code>–Ø —Ö–æ–¥–∏–ª –≤ –∫–∏–Ω–∞ –≤—á–µ—Ä–∞.</code>\n"
        "<code>–ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—å—Å—è —á–∏—Ç–∞—Ç—å –∫–Ω–∏–∂–∫–∏.</code>",
        parse_mode='HTML',
        reply_markup=get_main_keyboard()
    )
    return 8


async def process_spell_check(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏"""
    text = update.message.text

    if not text.strip():
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏",
                                        reply_markup=get_main_keyboard())
        return 8

    status_msg = await update.message.reply_text(
        "ü§ñ <i>–ò–ò –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é...</i>\n<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥</i>",
        parse_mode='HTML'
    )

    try:
        result = await analyzer.check_spelling(text)

        await context.bot.delete_message(
            chat_id=update.effective_chat.id,
            message_id=status_msg.message_id
        )

        if result.get('success', False):
            if not result.get('has_errors', False):
                response = (
                    f"‚úÖ <b>–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!</b>\n\n"
                    f"üìä <b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:</b>\n"
                    f"‚Ä¢ –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Å–ª–æ–≤: {result.get('total_words', 0)}\n"
                    f"‚Ä¢ –û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ\n"
                    f"‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞: {result.get('accuracy_score', 100)}%\n"
                    f"‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫: {result.get('source', 'unknown')}\n\n"
                )

                ai_comment = result.get('ai_comment', '')
                if ai_comment and '–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞' not in ai_comment.lower():
                    response += f"üí° <b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ò–ò:</b>\n{ai_comment}\n\n"

                response += "<i>–û—Ç–ª–∏—á–Ω–∞—è –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å! üëè</i>"

            else:
                response = f"‚ö†Ô∏è <b>–ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: {result.get('error_words', 0)}</b>\n\n"

                if result.get('errors'):
                    response += "<b>–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:</b>\n"
                    for i, (error, suggestion) in enumerate(zip(result['errors'], result['suggestions']), 1):
                        explanation = ""
                        if 'explanations' in result and i - 1 < len(result['explanations']):
                            explanation = f" <i>({result['explanations'][i - 1]})</i>"
                        response += f"{i}. <code>{error}</code> ‚Üí <b>{suggestion}</b>{explanation}\n"

                response += f"\nüìù <b>–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:</b>\n"
                response += f"<pre>{result.get('corrected_text', text)}</pre>\n\n"

                response += f"üìä <b>–î–µ—Ç–∞–ª–∏:</b>\n"
                response += f"‚Ä¢ –í—Å–µ–≥–æ —Å–ª–æ–≤: {result.get('total_words', 0)}\n"
                response += f"‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: {result.get('error_words', 0)}\n"
                response += f"‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞: {result.get('accuracy_score', 0)}%\n"

                ai_comment = result.get('ai_comment', '')
                if ai_comment and '–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞' not in ai_comment.lower():
                    response += f"üí° <b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ò–ò:</b>\n{ai_comment}\n\n"

                response += "<i>ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —Å –ø–æ–º–æ—â—å—é GigaChat AI</i>"
        else:
            ai_comment = result.get('ai_comment', '–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏')
            response = f"‚ö†Ô∏è <b>–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å</b>\n\n{ai_comment}"

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏: {e}")

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=status_msg.message_id
            )
        except:
            pass

        response = (
            "‚ö†Ô∏è <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ</b>\n\n"
            "<i>–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ—É–Ω–∫—Ü–∏—é.</i>"
        )

        await update.message.reply_html(response, reply_markup=get_main_keyboard())

    return 0


# ==================== –¢–ï–°–¢–û–í–ê–Ø –ö–û–ú–ê–ù–î–ê ====================

async def test_all(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–¢–µ—Å—Ç–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π"""
    test_text = "–±—ã—Å—Ç—Ä—ã–π"

    await update.message.reply_text(
        f"üß™ <b>–¢–µ—Å—Ç–∏—Ä—É—é –≤—Å–µ –ò–ò-—Ñ—É–Ω–∫—Ü–∏–∏ –Ω–∞ —Å–ª–æ–≤–µ: '{test_text}'</b>\n\n"
        f"<i>–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥...</i>",
        parse_mode='HTML'
    )

    results = []

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏
    test_cases = [
        ('üìä –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞', 'text_analysis', "–ë—ã—Å—Ç—Ä—ã–π —Ä—ã–∂–∏–π –ª–∏—Å –ø–µ—Ä–µ–ø—Ä—ã–≥–Ω—É–ª —á–µ—Ä–µ–∑ –ª–µ–Ω–∏–≤—É—é —Å–æ–±–∞–∫—É."),
        ('üî§ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è', 'morphology', test_text),
        ('üéµ –§–æ–Ω–µ—Ç–∏–∫–∞', 'phonetics', test_text),
        ('üìö –°–∏–Ω–æ–Ω–∏–º—ã', 'synonyms', test_text),
        ('üåç –Ø–∑—ã–∫', 'language_detection', "Hello world –∏ –ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ('üé® –°—Ç–∏–ª–∏—Å—Ç–∏–∫–∞', 'stylistics', "–ù—É –∫–æ—Ä–æ—á–µ —Ç–∏–ø–∞ –≤ –æ–±—â–µ–º —è –ø–æ—à–µ–ª"),
        ('üìú –≠—Ç–∏–º–æ–ª–æ–≥–∏—è', 'etymology', test_text),
    ]

    for name, analysis_type, text in test_cases:
        try:
            result = await analyzer.analyze(text, analysis_type)
            if result.get('success', False):
                results.append(f"‚úÖ {name}: –£—Å–ø–µ—à–Ω–æ")
            else:
                results.append(f"‚ö†Ô∏è {name}: –û—à–∏–±–∫–∞")
        except Exception as e:
            results.append(f"‚ùå {name}: –û—à–∏–±–∫–∞ ({str(e)[:50]})")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é
    grammar_text = "–Ø —Ö–æ—Ç–µ–ª –ø–æ–µ—Ö–∞—Ç—å –≤ –æ—Ç–ø—É—Å–∫ –∞ –Ω–∞ —Ä–∞–±–æ—Ç–µ —Å–∫–∞–∑–∞–ª–∏ —á—Ç–æ –Ω–∞–¥–æ —Ä–∞–±–æ—Ç–∞—Ç—å"
    try:
        grammar_result = await analyzer.check_grammar(grammar_text)
        if grammar_result.get('success', False):
            results.append(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: –ù–∞–π–¥–µ–Ω–æ {grammar_result.get('issue_count', 0)} –æ—à–∏–±–æ–∫")
        else:
            results.append("‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: –û—à–∏–±–∫–∞")
    except Exception:
        results.append("‚ùå –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏: –û—à–∏–±–∫–∞")

    spelling_text = "–ó–¥—Ä–∞—Å—Ç–≤—É–π—Ç–µ, –∫–∞–∫ –≤–∞—à–∏ –¥–µ–ª–∞?"
    try:
        spelling_result = await analyzer.check_spelling(spelling_text)
        if spelling_result.get('success', False):
            results.append(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏: –ù–∞–π–¥–µ–Ω–æ {spelling_result.get('error_words', 0)} –æ—à–∏–±–æ–∫")
        else:
            results.append("‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏: –û—à–∏–±–∫–∞")
    except Exception:
        results.append("‚ùå –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏: –û—à–∏–±–∫–∞")

    response = "üìã <b>–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ò–ò-—Ñ—É–Ω–∫—Ü–∏–π:</b>\n\n"
    response += "\n".join(results)
    response += "\n\n‚ú® <b>–í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —á–µ—Ä–µ–∑ GigaChat AI!</b>"

    await update.message.reply_html(response, reply_markup=get_main_keyboard())


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    gigachat_status = "‚úÖ GigaChat API –ø–æ–¥–∫–ª—é—á–µ–Ω" if GIGACHAT_CLIENT_ID and GIGACHAT_CLIENT_SECRET else "‚ö†Ô∏è GigaChat API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"

    help_text = f"""
ü§ñ <b>–ü–û–ú–û–©–¨ - –ë–û–¢-–õ–ò–ù–ì–í–ò–°–¢ –° –ü–û–õ–ù–´–ú –ò–ò-–ê–ù–ê–õ–ò–ó–û–ú</b>

<b>–°—Ç–∞—Ç—É—Å –ò–ò: {gigachat_status}</b>

‚ú® <b>–í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç GigaChat AI:</b>

<b>–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:</b>
‚Ä¢ üìä <b>–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ (–ò–ò)</b> - –ø–æ–ª–Ω—ã–π –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
‚Ä¢ ü§ñ <b>–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ (–ò–ò)</b> - –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è –∏ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
‚Ä¢ üîç <b>–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ (–ò–ò)</b> - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫

<b>–£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:</b>
‚Ä¢ üéµ <b>–§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–ò–ò)</b> - –∑–≤—É–∫–∏, —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è, —Å–ª–æ–≥–∏
‚Ä¢ üî§ <b>–ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è (–ò–ò)</b> - –ø–æ–ª–Ω—ã–π —Ä–∞–∑–±–æ—Ä —Å–ª–æ–≤–∞
‚Ä¢ üìö <b>–°–∏–Ω–æ–Ω–∏–º—ã (–ò–ò)</b> - —Å–∏–Ω–æ–Ω–∏–º—ã, –∞–Ω—Ç–æ–Ω–∏–º—ã, —ç—Ç–∏–º–æ–ª–æ–≥–∏—è
‚Ä¢ üåç <b>–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ (–ò–ò)</b> - –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑
‚Ä¢ üé® <b>–°—Ç–∏–ª–∏—Å—Ç–∏–∫–∞ (–ò–ò)</b> - –∞–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è –∏ —Ç–æ–Ω–∞
‚Ä¢ üìú <b>–≠—Ç–∏–º–æ–ª–æ–≥–∏—è (–ò–ò)</b> - –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —Å–ª–æ–≤

<b>–î–ª—è —Ä–∞–±–æ—Ç—ã –ò–ò –Ω—É–∂–Ω—ã –∫–ª—é—á–∏ GigaChat</b>
–ü–æ–ª—É—á–∏—Ç–µ –∫–ª—é—á–∏: https://developers.sber.ru/studio
- –ë–µ—Å–ø–ª–∞—Ç–Ω–æ: 1000 —Ç–æ–∫–µ–Ω–æ–≤ –≤ –¥–µ–Ω—å
- –¢—Ä–µ–±—É–µ—Ç—Å—è —É—á–µ—Ç–Ω–∞—è –∑–∞–ø–∏—Å—å –ì–æ—Å—É—Å–ª—É–≥

<b>–ö–æ–º–∞–Ω–¥—ã:</b>
/start - –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞
/test - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –ò–ò-—Ñ—É–Ω–∫—Ü–∏–∏
/help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
    """
    await update.message.reply_html(help_text, reply_markup=get_main_keyboard())
    return 0


async def handle_menu_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text

    if text == "üìä –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ (–ò–ò)":
        return await text_analysis_handler(update, context)
    elif text == "ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ (–ò–ò)":
        return await grammar_check_handler(update, context)
    elif text == "üéµ –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–ò–ò)":
        return await phonetics_handler(update, context)
    elif text == "üî§ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è (–ò–ò)":
        return await morphology_handler(update, context)
    elif text == "üìö –°–∏–Ω–æ–Ω–∏–º—ã (–ò–ò)":
        return await synonyms_handler(update, context)
    elif text == "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ (–ò–ò)":
        return await spell_check_handler(update, context)
    elif text == "üåç –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —è–∑—ã–∫ (–ò–ò)":
        return await language_detection_handler(update, context)
    elif text == "üé® –°—Ç–∏–ª–∏—Å—Ç–∏–∫–∞ (–ò–ò)":
        return await stylistics_handler(update, context)
    elif text == "üìú –≠—Ç–∏–º–æ–ª–æ–≥–∏—è (–ò–ò)":
        return await etymology_handler(update, context)
    elif text == "‚ùì –ü–æ–º–æ—â—å":
        return await help_command(update, context)
    else:
        await update.message.reply_text(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é –∏–∑ –º–µ–Ω—é –Ω–∏–∂–µ:",
            reply_markup=get_main_keyboard()
        )
        return 0


async def menu_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é. –í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é:",
        reply_markup=get_main_keyboard()
    )
    return 0


# ==================== –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ====================

def main():
    TOKEN = "8373843533:AAH9uigqO99bT2SFP9KssZbMfYqc7Ggfyfo"

    try:
        application = Application.builder().token(TOKEN).build()

        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∫–æ–º–∞–Ω–¥—É
        application.add_handler(CommandHandler('test', test_all))

        conv_handler = ConversationHandler(
            entry_points=[CommandHandler('start', start)],
            states={
                0: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_menu_selection)],
                1: [MessageHandler(filters.TEXT & ~filters.COMMAND, process_text_analysis)],
                2: [MessageHandler(filters.TEXT & ~filters.COMMAND, process_grammar_check)],
                3: [MessageHandler(filters.TEXT & ~filters.COMMAND, process_phonetics)],
                4: [MessageHandler(filters.TEXT & ~filters.COMMAND, process_morphology)],
                7: [MessageHandler(filters.TEXT & ~filters.COMMAND, process_synonyms)],
                8: [MessageHandler(filters.TEXT & ~filters.COMMAND, process_spell_check)],
                9: [MessageHandler(filters.TEXT & ~filters.COMMAND, process_language_detection)],
                10: [MessageHandler(filters.TEXT & ~filters.COMMAND, process_stylistics)],
                11: [MessageHandler(filters.TEXT & ~filters.COMMAND, process_etymology)],
            },
            fallbacks=[
                CommandHandler('start', start),
                CommandHandler('help', help_command),
                CommandHandler('menu', menu_command),
            ],
            allow_reentry=True
        )

        application.add_handler(conv_handler)
        application.add_handler(CommandHandler('help', help_command))
        application.add_handler(CommandHandler('menu', menu_command))

        print("=" * 50)
        print("ü§ñ –ë–û–¢-–õ–ò–ù–ì–í–ò–°–¢ –° –ü–û–õ–ù–´–ú –ò–ò-–ê–ù–ê–õ–ò–ó–û–ú")
        print("=" * 50)
        print("‚ú® –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç GigaChat AI:")
        print("   üìä –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞")
        print("   ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏")
        print("   üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏")
        print("   üéµ –§–æ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
        print("   üî§ –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è")
        print("   üìö –°–∏–Ω–æ–Ω–∏–º—ã")
        print("   üåç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞")
        print("   üé® –°—Ç–∏–ª–∏—Å—Ç–∏–∫–∞")
        print("   üìú –≠—Ç–∏–º–æ–ª–æ–≥–∏—è")

        if not GIGACHAT_CLIENT_ID or not GIGACHAT_CLIENT_SECRET:
            print("   ‚ö†Ô∏è  GigaChat API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        else:
            print("   ‚úÖ GigaChat API –Ω–∞—Å—Ç—Ä–æ–µ–Ω")

        print("\nüì± –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
        print("‚úÖ –ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
        print("=" * 50)

        application.run_polling()

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞: {e}")
        import traceback
        traceback.print_exc()


async def shutdown():
    """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
    await analyzer.close()


if __name__ == '__main__':
    try:
        import aiohttp

        print("‚úÖ aiohttp —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except ImportError:
        print("‚ùå aiohttp –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install aiohttp")
        sys.exit(1)

    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüõë –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        asyncio.run(shutdown())
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        asyncio.run(shutdown())